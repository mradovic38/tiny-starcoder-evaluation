{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mihai\\OneDrive\\Desktop\\AI Code Completion\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_fetcher import clone_repo, collect_python_files\n",
    "from split_generator import SplitGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sacrebleu import corpus_bleu\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning repository from https://github.com/mradovic38/football_analysis into repo...\n",
      "Repository cloned successfully.\n",
      "Collecting Python files from repo into code_examples...\n",
      "Copied: repo\\main.py -> code_examples\\main.py\n",
      "Copied: repo\\yolo_inf.py -> code_examples\\yolo_inf.py\n",
      "Copied: repo\\annotation\\abstract_annotator.py -> code_examples\\abstract_annotator.py\n",
      "Copied: repo\\annotation\\abstract_video_processor.py -> code_examples\\abstract_video_processor.py\n",
      "Copied: repo\\annotation\\football_video_processor.py -> code_examples\\football_video_processor.py\n",
      "Copied: repo\\annotation\\frame_number_annotator.py -> code_examples\\frame_number_annotator.py\n",
      "Copied: repo\\annotation\\keypoints_annotator.py -> code_examples\\keypoints_annotator.py\n",
      "Copied: repo\\annotation\\object_annotator.py -> code_examples\\object_annotator.py\n",
      "Copied: repo\\annotation\\projection_annotator.py -> code_examples\\projection_annotator.py\n",
      "Copied: repo\\ball_to_player_assignment\\ball_to_player_assigner.py -> code_examples\\ball_to_player_assigner.py\n",
      "Copied: repo\\ball_to_player_assignment\\possession_tracking\\possession_tracker.py -> code_examples\\possession_tracker.py\n",
      "Copied: repo\\club_assignment\\club.py -> code_examples\\club.py\n",
      "Copied: repo\\club_assignment\\club_assigner.py -> code_examples\\club_assigner.py\n",
      "Copied: repo\\file_writing\\abstract_writer.py -> code_examples\\abstract_writer.py\n",
      "Copied: repo\\file_writing\\tracks_json_writer.py -> code_examples\\tracks_json_writer.py\n",
      "Copied: repo\\position_mappers\\abstract_mapper.py -> code_examples\\abstract_mapper.py\n",
      "Copied: repo\\position_mappers\\homography.py -> code_examples\\homography.py\n",
      "Copied: repo\\position_mappers\\object_position_mapper.py -> code_examples\\object_position_mapper.py\n",
      "Copied: repo\\speed_estimation\\speed_estimator.py -> code_examples\\speed_estimator.py\n",
      "Copied: repo\\tracking\\abstract_tracker.py -> code_examples\\abstract_tracker.py\n",
      "Copied: repo\\tracking\\keypoints_tracker.py -> code_examples\\keypoints_tracker.py\n",
      "Copied: repo\\tracking\\object_tracker.py -> code_examples\\object_tracker.py\n",
      "Copied: repo\\utils\\bbox_utils.py -> code_examples\\bbox_utils.py\n",
      "Copied: repo\\utils\\color_utils.py -> code_examples\\color_utils.py\n",
      "Copied: repo\\utils\\video_utils.py -> code_examples\\video_utils.py\n",
      "Python file collection complete. Files are saved in code_examples.\n"
     ]
    }
   ],
   "source": [
    "REPO_URL = \"https://github.com/mradovic38/football_analysis\"\n",
    "\n",
    "# Clone the repository\n",
    "clone_repo(REPO_URL, clone_dir=\"repo\")\n",
    "\n",
    "# Collect all Python files from the cloned repository\n",
    "collect_python_files(\"repo\", target_dir=\"code_examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Tiny Starcoder model and tokenizer\n",
    "model_name = \"bigcode/tiny_starcoder_py\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Data Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_LENGTH = 200\n",
    "MIDDLE_LEGTH = 40\n",
    "SUFFIX_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 examples for file: code_examples\\ball_to_player_assigner.py\n",
      "Generated 1 examples for file: code_examples\\bbox_utils.py\n",
      "Generated 5 examples for file: code_examples\\club_assigner.py\n",
      "Generated 9 examples for file: code_examples\\football_video_processor.py\n",
      "Generated 2 examples for file: code_examples\\homography.py\n",
      "Generated 2 examples for file: code_examples\\keypoints_tracker.py\n",
      "Generated 3 examples for file: code_examples\\main.py\n",
      "Generated 5 examples for file: code_examples\\object_annotator.py\n",
      "Generated 1 examples for file: code_examples\\object_position_mapper.py\n",
      "Generated 2 examples for file: code_examples\\object_tracker.py\n",
      "Generated 4 examples for file: code_examples\\projection_annotator.py\n",
      "Generated 2 examples for file: code_examples\\speed_estimator.py\n",
      "Generated 2 examples for file: code_examples\\tracks_json_writer.py\n",
      "Generated 4 examples for file: code_examples\\video_utils.py\n"
     ]
    }
   ],
   "source": [
    "sg = SplitGenerator(tokenizer=tokenizer, directory='code_examples', \n",
    "                    middle_length=MIDDLE_LEGTH, prefix_length=PREFIX_LENGTH, suffix_length=SUFFIX_LENGTH)\n",
    "\n",
    "sg.generate('dataset/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>prefix</th>\n",
       "      <th>middle</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code_examples\\projection_annotator.py</td>\n",
       "      <td>=is_dark_color)\\n\\n        if 'ball' in tracks...</td>\n",
       "      <td>pos[1]) + 10), color=color, thickness=6)\\n\\n  ...</td>\n",
       "      <td>) -&gt; np.ndarray:\\n        \"\"\"\\n        Draws V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>code_examples\\tracks_json_writer.py</td>\n",
       "      <td>the file.\\n        \"\"\"\\n        # Convert all...</td>\n",
       "      <td>a JSON-serializable format.\\n\\n        Args:\\...</td>\n",
       "      <td>isinstance(obj, dict):\\n            # Ensure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>code_examples\\object_tracker.py</td>\n",
       "      <td>.model.predict(resized_frames, conf=self.conf)...</td>\n",
       "      <td>frame counter\\n        self.cur_frame += 1\\n\\...</td>\n",
       "      <td>np.ndarray) -&gt; np.ndarray:\\n        \"\"\"\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>code_examples\\football_video_processor.py</td>\n",
       "      <td>from .abstract_annotator import AbstractAnnota...</td>\n",
       "      <td>\\n    estimates speed, assigns the ball to pla...</td>\n",
       "      <td>: KeypointsTracker, \\n                 club_as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code_examples\\video_utils.py</td>\n",
       "      <td>frame capture: {e}\")\\n        finally:\\n     ...</td>\n",
       "      <td>frame processing: {e}\")\\n\\n        processed_...</td>\n",
       "      <td>int, np.ndarray]]) -&gt; None:\\n        \"\"\"\\n    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       fname  \\\n",
       "0      code_examples\\projection_annotator.py   \n",
       "1        code_examples\\tracks_json_writer.py   \n",
       "2            code_examples\\object_tracker.py   \n",
       "3  code_examples\\football_video_processor.py   \n",
       "4               code_examples\\video_utils.py   \n",
       "\n",
       "                                              prefix  \\\n",
       "0  =is_dark_color)\\n\\n        if 'ball' in tracks...   \n",
       "1   the file.\\n        \"\"\"\\n        # Convert all...   \n",
       "2  .model.predict(resized_frames, conf=self.conf)...   \n",
       "3  from .abstract_annotator import AbstractAnnota...   \n",
       "4   frame capture: {e}\")\\n        finally:\\n     ...   \n",
       "\n",
       "                                              middle  \\\n",
       "0  pos[1]) + 10), color=color, thickness=6)\\n\\n  ...   \n",
       "1   a JSON-serializable format.\\n\\n        Args:\\...   \n",
       "2   frame counter\\n        self.cur_frame += 1\\n\\...   \n",
       "3  \\n    estimates speed, assigns the ball to pla...   \n",
       "4   frame processing: {e}\")\\n\\n        processed_...   \n",
       "\n",
       "                                              suffix  \n",
       "0  ) -> np.ndarray:\\n        \"\"\"\\n        Draws V...  \n",
       "1   isinstance(obj, dict):\\n            # Ensure ...  \n",
       "2   np.ndarray) -> np.ndarray:\\n        \"\"\"\\n    ...  \n",
       "3  : KeypointsTracker, \\n                 club_as...  \n",
       "4  int, np.ndarray]]) -> None:\\n        \"\"\"\\n    ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/data.csv', delimiter='|').fillna('')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "# Ensure pad_token_id is set to a valid token (e.g., eos_token_id)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move model to device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to generate predictions for the middle part\n",
    "def get_completion(prefix: str, suffix: str) -> str:\n",
    "    # Prepare the input text\n",
    "    input_text = f\"<fim_prefix>{prefix}<fim_suffix>{suffix}<fim_middle>\"\n",
    "    \n",
    "    # Tokenize the input, ensuring it returns tensors\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    # Generate the completion\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],  # Use the correct tensor from tokenizer output\n",
    "            max_length=PREFIX_LENGTH + MIDDLE_LEGTH + SUFFIX_LENGTH, \n",
    "            pad_token_id=tokenizer.pad_token_id  # Ensure pad_token_id is passed\n",
    "        )\n",
    "    \n",
    "    # Decode the output and extract the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Extract the completion (text between prefix and suffix)\n",
    "    middle_start = generated_text.find(\"<fim_middle>\") + len(\"<fim_middle>\")\n",
    "    middle_end = generated_text.find(suffix, middle_start)\n",
    "    completion = generated_text[middle_start:middle_end].replace('<|endoftext|>', '')\n",
    "    \n",
    "    return completion\n",
    "\n",
    "# Generate predictions for each row in the DataFrame\n",
    "preds = df.apply(lambda row: get_completion(row['prefix'], row['suffix']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tiny Starcoder Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating Example by Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX:\n",
      "=is_dark_color)\n",
      "\n",
      "        if 'ball' in tracks:\n",
      "            for track_id, track_info in tracks['ball'].items():\n",
      "                proj_pos = track_info['projection']\n",
      "                self._draw_outline(frame, proj_pos, shape='plus', is_dark=is_color_dark((0, 255, 255)))\n",
      "                color = (0, 255, 255)\n",
      "                cv2.line(frame, (int(proj_pos[0]) - 10, int(proj_pos[1])), (int(proj_pos[0]) + 10, int(proj_pos[1])), color=color, thickness=6)\n",
      "                cv2.line(frame, (int(proj_pos[0]), int(proj_pos[1]) - 10), (int(proj_pos[0]), int(proj_\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      "pos[1]) + 10, color=color, thickness=6)\n",
      "                cv2.line(frame, (int(proj_pos[0]), int(pro\n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      "pos[1]) + 10), color=color, thickness=6)\n",
      "\n",
      "        return frame\n",
      "\n",
      "    def _draw_voronoi(self, image: np.ndarray, tracks: Dict\n",
      "**************************************************\n",
      "SUFFIX:\n",
      ") -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Draws Voronoi regions for players and goalkeepers on the frame.\n",
      "        \n",
      "        Parameters:\n",
      "            image (np.ndarray): The image on which to draw the Voronoi regions.\n",
      "            tracks (Dict): A dictionary containing tracking information for 'player' and 'goalkeeper'.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The frame with Voronoi regions drawn.\n",
      "        \"\"\"\n",
      "        height, width = image.shape[:2]\n",
      "        overlay = image.copy()\n",
      "        points, player_colors = [], []\n",
      "\n",
      "        for class_name in ['player', 'goalkeeper']:\n",
      "            track_data = tracks.get(class_name, {})\n",
      "            for track_id, track_info in track_data.items():\n",
      "                x, y = track_info['projection'][:2]\n",
      "                points.append([x, y])\n",
      "                player_colors.append(rgb_bgr_converter(track_info['club_color\n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      " the file.\n",
      "        \"\"\"\n",
      "        # Convert all tracks to a serializable format\n",
      "        serializable_tracks = self._make_serializable(tracks)\n",
      "\n",
      "        if os.path.exists(filename):\n",
      "            # If file exists, load existing data and append new tracks\n",
      "            with open(filename, 'r') as f:\n",
      "                existing_data = json.load(f)\n",
      "            existing_data.append(serializable_tracks)\n",
      "            data_to_save = existing_data\n",
      "        else:\n",
      "            # If file doesn't exist, create a new list with current tracks\n",
      "            data_to_save = [serializable_tracks]\n",
      "\n",
      "        # Write the serializable data to the file\n",
      "        with open(filename, 'w') as f:\n",
      "            json.dump(data_to_save, f, indent=4)  # Added indent for better readability\n",
      "\n",
      "    def _make_serializable(self, obj: Any) -> Any:\n",
      "        \"\"\"Recursively convert objects to\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      " serializable format.\n",
      "\n",
      "        Args:\n",
      "            obj (Any): Object to convert.\n",
      "\n",
      "        Returns:\n",
      "            Any: Serializable object.\n",
      "        \"\"\"\n",
      "        if isinstance(obj, dict):\n",
      "          \n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      " a JSON-serializable format.\n",
      "\n",
      "        Args:\n",
      "            obj (Any): The object to convert.\n",
      "\n",
      "        Returns:\n",
      "            Any: A JSON-serializable representation of the object.\n",
      "        \"\"\"\n",
      "        if\n",
      "**************************************************\n",
      "SUFFIX:\n",
      " isinstance(obj, dict):\n",
      "            # Ensure both keys and values are serializable\n",
      "            return {str(k): self._make_serializable(v) for k, v in obj.items()}\n",
      "        elif isinstance(obj, list):\n",
      "            # Convert lists recursively\n",
      "            return [self._make_serializable(v) for v in obj]\n",
      "        elif isinstance(obj, tuple):\n",
      "            # Convert tuples recursively\n",
      "            return tuple(self._make_serializable(v) for v in obj)\n",
      "        elif isinstance(obj, np.ndarray):\n",
      "            # Convert numpy arrays to lists\n",
      "            return obj.tolist()\n",
      "        elif isinstance(obj, (np.integer, np.int32, np.int64)):\n",
      "            # Convert numpy int to Python int\n",
      "            return int(obj)\n",
      "        elif isinstance(obj, (np.floating, np.float32, np.float64)):\n",
      "            # Convert numpy float to Python float\n",
      "            return float(obj)\n",
      "       \n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      ".model.predict(resized_frames, conf=self.conf)\n",
      "\n",
      "        return detections  # Batch of detections\n",
      "\n",
      "    def track(self, detection: Results) -> dict:\n",
      "        \"\"\"\n",
      "        Perform object tracking on detection.\n",
      "\n",
      "        Args:\n",
      "            detection (Results): Detected objects for a single frame.\n",
      "\n",
      "        Returns:\n",
      "            dict: Dictionary containing tracks of the frame.\n",
      "        \"\"\"\n",
      "        # Convert Ultralytics detections to supervision\n",
      "        detection_sv = sv.Detections.from_ultralytics(detection)\n",
      "\n",
      "        # Perform ByteTracker object tracking on the detections\n",
      "        tracks = self.tracker.update_with_detections(detection_sv)\n",
      "\n",
      "        self.current_frame_tracks = self._tracks_mapper(tracks, self.classes)\n",
      "        \n",
      "        # Store the current frame's tracking information in all_tracks\n",
      "        self.all_tracks[self.cur_frame] = self.current_frame_tracks.copy()\n",
      "\n",
      "        # Increment the current\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      " tracks counter\n",
      "        self.current_frame_tracks += 1\n",
      "\n",
      "        return tracks\n",
      "\n",
      "    def _get_frame_id(self, frame: np.ndarray) -> int:\n",
      "      \n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      " frame counter\n",
      "        self.cur_frame += 1\n",
      "\n",
      "        # Return only the last frame's data\n",
      "        return self.current_frame_tracks\n",
      "    \n",
      "    def _preprocess_frame(self, frame:\n",
      "**************************************************\n",
      "SUFFIX:\n",
      " np.ndarray) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Preprocess the frame by resizing it to 1280x1280.\n",
      "\n",
      "        Args:\n",
      "            frame (np.ndarray): The input image frame.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The resized frame.\n",
      "        \"\"\"\n",
      "        # Resize the frame to 1280x1280\n",
      "        resized_frame = cv2.resize(frame, (1280, 1280))\n",
      "        return resized_frame\n",
      "    \n",
      "    def _tracks_mapper(self, tracks: sv.Detections, class_names: List[str]) -> dict:\n",
      "        \"\"\"\n",
      "        Maps tracks to a dictionary by class and tracker ID. Also, adjusts bounding boxes to 1920x1080 resolution.\n",
      "\n",
      "        Args:\n",
      "            tracks (sv.Detections): Tracks from the frame.\n",
      "            class_names (List[str]): List of class names.\n",
      "\n",
      "       \n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      "from .abstract_annotator import AbstractAnnotator\n",
      "from .abstract_video_processor import AbstractVideoProcessor\n",
      "from .object_annotator import ObjectAnnotator\n",
      "from .keypoints_annotator import KeypointsAnnotator\n",
      "from .projection_annotator import ProjectionAnnotator\n",
      "from position_mappers import ObjectPositionMapper\n",
      "from speed_estimation import SpeedEstimator\n",
      "from .frame_number_annotator import FrameNumberAnnotator\n",
      "from file_writing import TracksJsonWriter\n",
      "from tracking import ObjectTracker, KeypointsTracker\n",
      "from club_assignment import ClubAssigner\n",
      "from ball_to_player_assignment import BallToPlayerAssigner\n",
      "from utils import rgb_bgr_converter\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "from typing import List, Dict, Optional, Tuple\n",
      "\n",
      "class FootballVideoProcessor(AbstractAnnotator, AbstractVideoProcessor):\n",
      "    \"\"\"\n",
      "    A video processor for football footage that tracks objects and keypoints,\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      "\n",
      "    and saves them to a json file.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, \n",
      "                 obj_tracker: ObjectTracker, \n",
      "                 kp_tracker: KeypointsTracker, \n",
      "                 clu\n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      "\n",
      "    estimates speed, assigns the ball to player, calculates the ball possession \n",
      "    and adds various annotations.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, obj_tracker: ObjectTracker, kp_tracker\n",
      "**************************************************\n",
      "SUFFIX:\n",
      ": KeypointsTracker, \n",
      "                 club_assigner: ClubAssigner, ball_to_player_assigner: BallToPlayerAssigner, \n",
      "                 top_down_keypoints: np.ndarray, field_img_path: str, \n",
      "                 save_tracks_dir: Optional[str] = None, draw_frame_num: bool = True) -> None:\n",
      "        \"\"\"\n",
      "        Initializes the video processor with necessary components for tracking, annotations, and saving tracks.\n",
      "\n",
      "        Args:\n",
      "            obj_tracker (ObjectTracker): The object tracker for tracking players and balls.\n",
      "            kp_tracker (KeypointsTracker): The keypoints tracker for detecting and tracking keypoints.\n",
      "            club_assigner (ClubAssigner): Assigner to determine clubs for the tracked players.\n",
      "            ball_to_player_assigner (BallToPlayerAssigner): Assigns the ball to a specific player based on tracking.\n",
      "            top_down_keypoints (np.ndarray): Key\n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      " frame capture: {e}\")\n",
      "        finally:\n",
      "            cap.release()\n",
      "            frame_queue.put(None)  # Signal end of capture\n",
      "        print(\"Frame capture complete\")\n",
      "\n",
      "    def frame_processing_thread() -> None:\n",
      "        \"\"\"Thread to process frames from the frame queue.\"\"\"\n",
      "        \n",
      "        print(\"Starting frame processing\")\n",
      "        frame_batch = []\n",
      "        while not stop_event.is_set():\n",
      "            try:\n",
      "                item = frame_queue.get(timeout=1)\n",
      "                if item is None:\n",
      "                    print(\"No more frames to process\")\n",
      "                    if frame_batch:\n",
      "                        process_batch(frame_batch)\n",
      "                    break\n",
      "                frame_count, frame = item\n",
      "                frame_batch.append((frame_count, frame))\n",
      "\n",
      "                if len(frame_batch) == batch_size:\n",
      "                    process_batch(frame_batch)\n",
      "                    frame_batch = []\n",
      "            except queue.Empty:\n",
      "                continue\n",
      "            except Exception as e:\n",
      "                print(f\"Error in\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      " frame processing: {e}\")\n",
      "                traceback.print_exc()\n",
      "\n",
      "    def process(\n",
      "        processor: Processor,\n",
      "        batch: List[Tuple[int, np.ndarray]],\n",
      "        fp\n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      " frame processing: {e}\")\n",
      "\n",
      "        processed_queue.put(None)  # Signal end of processing\n",
      "        print(\"Frame processing complete\")\n",
      "\n",
      "    def process_batch(batch: List[Tuple[\n",
      "**************************************************\n",
      "SUFFIX:\n",
      "int, np.ndarray]]) -> None:\n",
      "        \"\"\"\n",
      "        Process a batch of frames and put results in the processed queue.\n",
      "\n",
      "        Args:\n",
      "            batch (List[Tuple[int, np.ndarray]]): List of tuples containing frame count and frame data.\n",
      "        \"\"\"\n",
      "        frames = [frame for _, frame in batch]\n",
      "        try:\n",
      "            processed_batch = processor.process(frames, fps)\n",
      "            for (frame_count, _), processed_frame in zip(batch, processed_batch):\n",
      "                processed_queue.put((frame_count, processed_frame))\n",
      "        except Exception as e:\n",
      "            print(f\"Error processing batch: {e}\")\n",
      "            traceback.print_exc()\n",
      "\n",
      "    def frame_display_thread(temp_dir: str) -> None:\n",
      "        \"\"\"Thread to display processed frames.\"\"\"\n",
      "\n",
      "        print(\"Starting frame display\")\n",
      "        while not stop_event.is_set():\n",
      "            try:\n",
      "                item = processed_queue.get(timeout=1)\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('PREFIX:')\n",
    "    print(df['prefix'][i])\n",
    "    print('*'*50)\n",
    "    print('MIDDLE PREDICTION:')\n",
    "    print(preds[i])\n",
    "    print('*'*50)\n",
    "    print('MIDDLE TRUE:')\n",
    "    print(df['middle'][i])\n",
    "    print('*'*50)\n",
    "    print('SUFFIX:')\n",
    "    print(df['suffix'][i])\n",
    "    print('_'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Evaluating using Different Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df.drop(columns=['fname']).copy()\n",
    "res['mid_pred'] = preds\n",
    "\n",
    "# Preprocess function for cleaning the text\n",
    "def preprocess(text):\n",
    "    return text.strip().lower()\n",
    "\n",
    "res['middle'] = res['middle'].apply(preprocess)\n",
    "res['mid_pred'] = res['mid_pred'].apply(preprocess)\n",
    "\n",
    "\n",
    "res['mid_pred'] = res['mid_pred'].fillna('')\n",
    "\n",
    "# Calculate Exact Match\n",
    "def exact_match(row):\n",
    "    return row['middle'] == row['mid_pred']\n",
    "\n",
    "def calculate_bleu(reference, hypothesis):\n",
    "    # Apply smoothing to avoid 0 BLEU score\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "    # Calculate BLEU score with smoothing\n",
    "    bleu_score = sentence_bleu(reference, hypothesis, smoothing_function=smoothing_function)\n",
    "\n",
    "    return bleu_score\n",
    "\n",
    "res['exact_match'] = res.apply(exact_match, axis=1)\n",
    "\n",
    "# Calculate chrF score\n",
    "res['chrf'] = res.apply(lambda row: corpus_bleu([row['mid_pred']], [[row['middle']]]).score, axis=1)\n",
    "\n",
    "# Calculate BLEU score\n",
    "res['bleu'] = res.apply(lambda row: calculate_bleu([row['middle'].split()], row['mid_pred'].split()), axis=1)\n",
    "\n",
    "# Calculate ROUGE score\n",
    "def calculate_rouge(row):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(row['middle'], row['mid_pred'])\n",
    "    return scores\n",
    "\n",
    "res['rouge'] = res.apply(calculate_rouge, axis=1)\n",
    "\n",
    "# Combine results\n",
    "results = {\n",
    "    'exact_match': np.mean(res['exact_match']),\n",
    "    'chrf': np.mean(res['chrf']),\n",
    "    'bleu': np.mean(res['bleu']),\n",
    "    'rouge1': res['rouge'].apply(lambda x: x['rouge1'].fmeasure).mean(),\n",
    "    'rouge2': res['rouge'].apply(lambda x: x['rouge2'].fmeasure).mean(),\n",
    "    'rougeL': res['rouge'].apply(lambda x: x['rougeL'].fmeasure).mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Score: 0.00\n",
      "Character-Level F Score: 43.52\n",
      "BLEU: 0.21\n",
      "Rouge-1: 0.54\n",
      "Rouge-2: 0.41\n",
      "Rouge-L: 0.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Exact Match Score: {results['exact_match']:.2f}\")\n",
    "print(f\"Character-Level F Score: {results['chrf']:.2f}\")\n",
    "print(f\"BLEU: {results['bleu']:.2f}\")\n",
    "print(f\"Rouge-1: {results['rouge1']:.2f}\")\n",
    "print(f\"Rouge-2: {results['rouge2']:.2f}\")\n",
    "print(f\"Rouge-L: {results['rougeL']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final thoughts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
