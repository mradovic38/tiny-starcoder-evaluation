{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mihai\\OneDrive\\Desktop\\AI Code Completion\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_fetcher import clone_repo, collect_python_files\n",
    "from split_generator import SplitGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning repository from https://github.com/mradovic38/football_analysis into repo...\n",
      "Repository cloned successfully.\n",
      "Collecting Python files from repo into code_examples...\n",
      "Copied: repo\\main.py -> code_examples\\main.py\n",
      "Copied: repo\\yolo_inf.py -> code_examples\\yolo_inf.py\n",
      "Copied: repo\\annotation\\abstract_annotator.py -> code_examples\\abstract_annotator.py\n",
      "Copied: repo\\annotation\\abstract_video_processor.py -> code_examples\\abstract_video_processor.py\n",
      "Copied: repo\\annotation\\football_video_processor.py -> code_examples\\football_video_processor.py\n",
      "Copied: repo\\annotation\\frame_number_annotator.py -> code_examples\\frame_number_annotator.py\n",
      "Copied: repo\\annotation\\keypoints_annotator.py -> code_examples\\keypoints_annotator.py\n",
      "Copied: repo\\annotation\\object_annotator.py -> code_examples\\object_annotator.py\n",
      "Copied: repo\\annotation\\projection_annotator.py -> code_examples\\projection_annotator.py\n",
      "Copied: repo\\ball_to_player_assignment\\ball_to_player_assigner.py -> code_examples\\ball_to_player_assigner.py\n",
      "Copied: repo\\ball_to_player_assignment\\possession_tracking\\possession_tracker.py -> code_examples\\possession_tracker.py\n",
      "Copied: repo\\club_assignment\\club.py -> code_examples\\club.py\n",
      "Copied: repo\\club_assignment\\club_assigner.py -> code_examples\\club_assigner.py\n",
      "Copied: repo\\file_writing\\abstract_writer.py -> code_examples\\abstract_writer.py\n",
      "Copied: repo\\file_writing\\tracks_json_writer.py -> code_examples\\tracks_json_writer.py\n",
      "Copied: repo\\position_mappers\\abstract_mapper.py -> code_examples\\abstract_mapper.py\n",
      "Copied: repo\\position_mappers\\homography.py -> code_examples\\homography.py\n",
      "Copied: repo\\position_mappers\\object_position_mapper.py -> code_examples\\object_position_mapper.py\n",
      "Copied: repo\\speed_estimation\\speed_estimator.py -> code_examples\\speed_estimator.py\n",
      "Copied: repo\\tracking\\abstract_tracker.py -> code_examples\\abstract_tracker.py\n",
      "Copied: repo\\tracking\\keypoints_tracker.py -> code_examples\\keypoints_tracker.py\n",
      "Copied: repo\\tracking\\object_tracker.py -> code_examples\\object_tracker.py\n",
      "Copied: repo\\utils\\bbox_utils.py -> code_examples\\bbox_utils.py\n",
      "Copied: repo\\utils\\color_utils.py -> code_examples\\color_utils.py\n",
      "Copied: repo\\utils\\video_utils.py -> code_examples\\video_utils.py\n",
      "Python file collection complete. Files are saved in code_examples.\n"
     ]
    }
   ],
   "source": [
    "REPO_URL = \"https://github.com/mradovic38/football_analysis\"\n",
    "\n",
    "# Clone the repository\n",
    "clone_repo(REPO_URL, clone_dir=\"repo\")\n",
    "\n",
    "# Collect all Python files from the cloned repository\n",
    "collect_python_files(\"repo\", target_dir=\"code_examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating Data Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 examples for file: code_examples\\abstract_tracker.py\n",
      "Generated 1 examples for file: code_examples\\abstract_video_processor.py\n",
      "Generated 9 examples for file: code_examples\\ball_to_player_assigner.py\n",
      "Generated 5 examples for file: code_examples\\bbox_utils.py\n",
      "Generated 17 examples for file: code_examples\\club_assigner.py\n",
      "Generated 3 examples for file: code_examples\\color_utils.py\n",
      "Generated 12 examples for file: code_examples\\football_video_processor.py\n",
      "Generated 3 examples for file: code_examples\\frame_number_annotator.py\n",
      "Generated 6 examples for file: code_examples\\homography.py\n",
      "Generated 3 examples for file: code_examples\\keypoints_annotator.py\n",
      "Generated 5 examples for file: code_examples\\keypoints_tracker.py\n",
      "Generated 4 examples for file: code_examples\\main.py\n",
      "Generated 5 examples for file: code_examples\\object_annotator.py\n",
      "Generated 2 examples for file: code_examples\\object_position_mapper.py\n",
      "Generated 10 examples for file: code_examples\\object_tracker.py\n",
      "Generated 3 examples for file: code_examples\\possession_tracker.py\n",
      "Generated 3 examples for file: code_examples\\projection_annotator.py\n",
      "Generated 7 examples for file: code_examples\\speed_estimator.py\n",
      "Generated 8 examples for file: code_examples\\tracks_json_writer.py\n",
      "Generated 9 examples for file: code_examples\\video_utils.py\n",
      "Generated 1 examples for file: code_examples\\yolo_inf.py\n"
     ]
    }
   ],
   "source": [
    "sg = SplitGenerator('code_examples', max_chars=256)\n",
    "\n",
    "sg.generate('dataset/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>prefix</th>\n",
       "      <th>middle</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code_examples\\ball_to_player_assigner.py</td>\n",
       "      <td>from utils import point_distance, get_bbox_cen...</td>\n",
       "      <td>from .possession_tracking import PossessionTra...</td>\n",
       "      <td>from typing import Dict, Tuple, Any\\n\\nclass B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>code_examples\\club_assigner.py</td>\n",
       "      <td>def predict(self, extracted_color: Tuple[i...</td>\n",
       "      <td>\"\"\"\\n        Predict the club for a gi...</td>\n",
       "      <td>\\n        Args:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>code_examples\\bbox_utils.py</td>\n",
       "      <td>def point_coord_diff(p1: Tuple[float, float], ...</td>\n",
       "      <td>Calculate the coordinate differences betwe...</td>\n",
       "      <td>Args:\\n        p1 (Tuple[float, float]): T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>code_examples\\projection_annotator.py</td>\n",
       "      <td>Parameters:\\n            frame (np.nda...</td>\n",
       "      <td>pos (tuple): The (x, y) position o...</td>\n",
       "      <td>shape (str): The shape of the outl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code_examples\\club_assigner.py</td>\n",
       "      <td>return (int(jersey_color_bgr[2]), int(...</td>\n",
       "      <td>\\n    def save_player_image(self, img: np.ndar...</td>\n",
       "      <td>\"\"\"\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fname  \\\n",
       "0  code_examples\\ball_to_player_assigner.py   \n",
       "1            code_examples\\club_assigner.py   \n",
       "2               code_examples\\bbox_utils.py   \n",
       "3     code_examples\\projection_annotator.py   \n",
       "4            code_examples\\club_assigner.py   \n",
       "\n",
       "                                              prefix  \\\n",
       "0  from utils import point_distance, get_bbox_cen...   \n",
       "1      def predict(self, extracted_color: Tuple[i...   \n",
       "2  def point_coord_diff(p1: Tuple[float, float], ...   \n",
       "3          Parameters:\\n            frame (np.nda...   \n",
       "4          return (int(jersey_color_bgr[2]), int(...   \n",
       "\n",
       "                                              middle  \\\n",
       "0  from .possession_tracking import PossessionTra...   \n",
       "1          \"\"\"\\n        Predict the club for a gi...   \n",
       "2      Calculate the coordinate differences betwe...   \n",
       "3              pos (tuple): The (x, y) position o...   \n",
       "4  \\n    def save_player_image(self, img: np.ndar...   \n",
       "\n",
       "                                              suffix  \n",
       "0  from typing import Dict, Tuple, Any\\n\\nclass B...  \n",
       "1                                  \\n        Args:\\n  \n",
       "2      Args:\\n        p1 (Tuple[float, float]): T...  \n",
       "3              shape (str): The shape of the outl...  \n",
       "4                                              \"\"\"\\n  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/data.csv', delimiter='|').fillna('')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    A video processor for football footage that tracks objects and keypoints,\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['suffix'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Load the Tiny Starcoder model and tokenizer\n",
    "model_name = \"bigcode/tiny_starcoder_py\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Ensure pad_token_id is set to a valid token (e.g., eos_token_id)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move model to device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to generate predictions for the middle part\n",
    "def get_completion(prefix, suffix, max_new_tokens=50):\n",
    "    # Prepare the input text\n",
    "    input_text = f\"<fim_prefix>{prefix}<fim_suffix>{suffix}<fim_middle>\"\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate the completion\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs, \n",
    "            max_length=256\n",
    "        )\n",
    "    \n",
    "    # Decode and return the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0])\n",
    "    \n",
    "    # Extract the completion (text between prefix and suffix)\n",
    "    completion = generated_text.split(\"<fim_middle>\")[1].split(suffix)[0]\n",
    "    \n",
    "    return completion\n",
    "\n",
    "# Generate predictions for each row in the DataFrame\n",
    "preds = df[:5].apply(lambda row: get_completion(row['prefix'], row['suffix']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fim_prefix>def print_one_two_three():\n",
      "    print('one')\n",
      "    <fim_suffix>\n",
      "    print('three')<fim_middle>print('two')\n",
      "    print('three')<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"<fim_prefix>def print_one_two_three():\\n    print('one')\\n    <fim_suffix>\\n    print('three')<fim_middle>\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_length=128)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFIX:\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any\n",
      "\n",
      "class AbstractWriter(ABC):\n",
      "    \"\"\"An abstract base class for writing data to a file.\"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    def write(self, filename: str, data: Any) -> None:\n",
      "**************************************************\n",
      "\n",
      "MIDDLE TRUE:\n",
      "        \"\"\"Save data to a file.\n",
      "\n",
      "        Args:\n",
      "            filename (str): The name of the file to save the data.\n",
      "            data (Any): The data to be saved.\n",
      "        \"\"\"\n",
      "        pass\n",
      "        \n",
      "    @abstractmethod\n",
      "    def _make_serializable(self, obj: Any) -> Any:\n",
      "**************************************************\n",
      "\n",
      "SUFFIX:\n",
      "        \"\"\"Convert objects to a serializable format.\n",
      "\n",
      "        Args:\n",
      "            obj (Any): The object to convert.\n",
      "\n",
      "        Returns:\n",
      "            Any: A serializable representation of the object.\n",
      "        \"\"\"\n",
      "        pass\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "PREFIX:\n",
      "from .abstract_annotator import AbstractAnnotator\n",
      "from utils import is_color_dark, rgb_bgr_converter\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "from scipy.spatial import Voronoi\n",
      "from typing import Dict\n",
      "\n",
      "\n",
      "class ProjectionAnnotator(AbstractAnnotator):\n",
      "    \"\"\"\n",
      "    Class to annotate projections on a projection image, including Voronoi regions for players (and goalkeepers), \n",
      "    and different markers for ball, players, referees, and goalkeepers.\n",
      "    \"\"\"\n",
      "\n",
      "    def _draw_outline(self, frame: np.ndarray, pos: tuple, shape: str = 'circle', size: int = 10, is_dark: bool = True) -> None:\n",
      "**************************************************\n",
      "\n",
      "MIDDLE TRUE:\n",
      "        \"\"\"\n",
      "        Draws a white or black outline around the object based on its color and shape.\n",
      "        \n",
      "        Parameters:\n",
      "            frame (np.ndarray): The image on which to draw the outline.\n",
      "            pos (tuple): The (x, y) position of the object.\n",
      "            shape (str): The shape of the outline ('circle', 'square', 'dashed_circle', 'plus').\n",
      "            size (int): The size of the outline.\n",
      "            is_dark (bool): Flag indicating whether the color is dark (determines outline color).\n",
      "        \"\"\"\n",
      "        outline_color = (255, 255, 255) if is_dark else (0, 0, 0)\n",
      "\n",
      "        if shape == 'circle':\n",
      "            cv2.circle(frame, (int(pos[0]), int(pos[1])), radius=size + 2, color=outline_color, thickness=2)\n",
      "        elif shape == 'square':\n",
      "            top_left = (int(pos[0]) - (size + 2), int(pos[1]) - (size + 2))\n",
      "            bottom_right = (int(pos[0]) + (size + 2), int(pos[1]) + (size + 2))\n",
      "            cv2.rectangle(frame, top_left, bottom_right, color=outline_color, thickness=2)\n",
      "        elif shape == 'dashed_circle':\n",
      "            dash_length, gap_length = 30, 30\n",
      "            for i in range(0, 360, dash_length + gap_length):\n",
      "                start_angle_rad, end_angle_rad = np.radians(i), np.radians(i + dash_length)\n",
      "                start_x = int(pos[0]) + int((size + 2) * np.cos(start_angle_rad))\n",
      "                start_y = int(pos[1]) + int((size + 2) * np.sin(start_angle_rad))\n",
      "                end_x = int(pos[0]) + int((size + 2) * np.cos(end_angle_rad))\n",
      "                end_y = int(pos[1]) + int((size + 2) * np.sin(end_angle_rad))\n",
      "                cv2.line(frame, (start_x, start_y), (end_x, end_y), color=(0, 0, 0), thickness=2)\n",
      "        elif shape == 'plus':\n",
      "            cv2.line(frame, (int(pos[0]) - size, int(pos[1])), (int(pos[0]) + size, int(pos[1])), color=outline_color, thickness=10)\n",
      "            cv2.line(frame, (int(pos[0]), int(pos[1]) - size), (int(pos[0]), int(pos[1]) + size), color=outline_color, thickness=10)\n",
      "\n",
      "\n",
      "    def annotate(self, frame: np.ndarray, tracks: Dict) -> np.ndarray:\n",
      "**************************************************\n",
      "\n",
      "SUFFIX:\n",
      "        \"\"\"\n",
      "        Annotates an image with projected player, goalkeeper, referee, and ball positions, along with Voronoi regions.\n",
      "        \n",
      "        Parameters:\n",
      "            frame (np.ndarray): The image on which to draw the annotations.\n",
      "            tracks (Dict): A dictionary containing tracking information for 'player', 'goalkeeper', 'referee', and 'ball'.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The annotated frame.\n",
      "        \"\"\"\n",
      "        frame = frame.copy()\n",
      "        frame = self._draw_voronoi(frame, tracks)\n",
      "\n",
      "        for class_name, track_data in tracks.items():\n",
      "            if class_name != 'ball':  # Ball is drawn later\n",
      "                for track_id, track_info in track_data.items():\n",
      "                    proj_pos = track_info['projection']\n",
      "                    color = track_info.get('club_color', (255, 255, 255))\n",
      "                    color = rgb_bgr_converter(color)\n",
      "                    is_dark_color = is_color_dark(color)\n",
      "\n",
      "                    if class_name in ['player', 'goalkeeper']:\n",
      "                        shape = 'square' if class_name == 'goalkeeper' else 'circle'\n",
      "                        self._draw_outline(frame, proj_pos, shape=shape, is_dark=is_dark_color)\n",
      "\n",
      "                        if track_info.get('has_ball', False):\n",
      "                            cv2.circle(frame, (int(proj_pos[0]), int(proj_pos[1])), radius=15, color=(0, 255, 0), thickness=2)\n",
      "                        if shape == 'circle':\n",
      "                            cv2.circle(frame, (int(proj_pos[0]), int(proj_pos[1])), radius=10, color=color, thickness=-1)\n",
      "                        else:\n",
      "                            top_left = (int(proj_pos[0]) - 10, int(proj_pos[1]) - 10)\n",
      "                            bottom_right = (int(proj_pos[0]) + 10, int(proj_pos[1]) + 10)\n",
      "                            cv2.rectangle(frame, top_left, bottom_right, color=color, thickness=-1)\n",
      "\n",
      "                    elif class_name == 'referee':\n",
      "                        self._draw_outline(frame, proj_pos, shape='dashed_circle', is_dark=is_dark_color)\n",
      "\n",
      "        if 'ball' in tracks:\n",
      "            for track_id, track_info in tracks['ball'].items():\n",
      "                proj_pos = track_info['projection']\n",
      "                self._draw_outline(frame, proj_pos, shape='plus', is_dark=is_color_dark((0, 255, 255)))\n",
      "                color = (0, 255, 255)\n",
      "                cv2.line(frame, (int(proj_pos[0]) - 10, int(proj_pos[1])), (int(proj_pos[0]) + 10, int(proj_pos[1])), color=color, thickness=6)\n",
      "                cv2.line(frame, (int(proj_pos[0]), int(proj_pos[1]) - 10), (int(proj_pos[0]), int(proj_pos[1]) + 10), color=color, thickness=6)\n",
      "\n",
      "        return frame\n",
      "\n",
      "    def _draw_voronoi(self, image: np.ndarray, tracks: Dict) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Draws Voronoi regions for players and goalkeepers on the frame.\n",
      "        \n",
      "        Parameters:\n",
      "            image (np.ndarray): The image on which to draw the Voronoi regions.\n",
      "            tracks (Dict): A dictionary containing tracking information for 'player' and 'goalkeeper'.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The frame with Voronoi regions drawn.\n",
      "        \"\"\"\n",
      "        height, width = image.shape[:2]\n",
      "        overlay = image.copy()\n",
      "        points, player_colors = [], []\n",
      "\n",
      "        for class_name in ['player', 'goalkeeper']:\n",
      "            track_data = tracks.get(class_name, {})\n",
      "            for track_id, track_info in track_data.items():\n",
      "                x, y = track_info['projection'][:2]\n",
      "                points.append([x, y])\n",
      "                player_colors.append(rgb_bgr_converter(track_info['club_color']))\n",
      "\n",
      "        boundary_margin = 1000\n",
      "        boundary_points = [\n",
      "            [-boundary_margin, -boundary_margin], [width // 2, -boundary_margin],\n",
      "            [width + boundary_margin, -boundary_margin], [-boundary_margin, height // 2],\n",
      "            [width + boundary_margin, height // 2], [-boundary_margin, height + boundary_margin],\n",
      "            [width // 2, height + boundary_margin], [width + boundary_margin, height + boundary_margin]\n",
      "        ]\n",
      "        boundary_color = (128, 128, 128)\n",
      "        points.extend(boundary_points)\n",
      "        player_colors.extend([boundary_color] * len(boundary_points))\n",
      "\n",
      "        if len(points) > 2:\n",
      "            points = np.array(points)\n",
      "            vor = Voronoi(points)\n",
      "            for region_index, region in enumerate(vor.point_region):\n",
      "                if -1 not in vor.regions[region] and len(vor.regions[region]) > 0:\n",
      "                    polygon = [vor.vertices[i] for i in vor.regions[region]]\n",
      "                    polygon = np.array(polygon, np.int32).reshape((-1, 1, 2))\n",
      "                    color = player_colors[region_index] if region_index < len(player_colors) else boundary_color\n",
      "                    cv2.polylines(overlay, [polygon], isClosed=True, color=color, thickness=2)\n",
      "                    cv2.fillPoly(overlay, [polygon], color=color)\n",
      "\n",
      "        alpha = 0.6\n",
      "        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
      "        \n",
      "        return image\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "PREFIX:\n",
      "from abc import ABC, abstractmethod\n",
      "from ultralytics import YOLO\n",
      "import torch\n",
      "from typing import Any, Dict, List\n",
      "from ultralytics.engine.results import Results\n",
      "import numpy as np\n",
      "\n",
      "class AbstractTracker(ABC):\n",
      "\n",
      "    def __init__(self, model_path: str, conf: float = 0.1) -> None:\n",
      "**************************************************\n",
      "\n",
      "MIDDLE TRUE:\n",
      "        \"\"\"\n",
      "        Load the model from the given path and set the confidence threshold.\n",
      "\n",
      "        Args:\n",
      "            model_path (str): Path to the model.\n",
      "            conf (float): Confidence threshold for detections.\n",
      "        \"\"\"\n",
      "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "        self.model = YOLO(model_path)\n",
      "        self.model.to(device)\n",
      "        self.conf = conf  # Set confidence threshold\n",
      "        self.cur_frame = 0  # Initialize current frame counter\n",
      "\n",
      "    @abstractmethod\n",
      "    def detect(self, frames: List[np.ndarray]) -> List[Results]:\n",
      "        \"\"\"\n",
      "        Abstract method for YOLO detection.\n",
      "\n",
      "        Args:\n",
      "            frames (List[np.ndarray]): List of frames for detection.\n",
      "\n",
      "        Returns:\n",
      "            List[Results]: List of YOLO detection result objects.\n",
      "        \"\"\"\n",
      "        pass\n",
      "        \n",
      "    @abstractmethod\n",
      "    def track(self, detection: Results) -> dict:\n",
      "**************************************************\n",
      "\n",
      "SUFFIX:\n",
      "        \"\"\"\n",
      "        Abstract method for tracking detections.\n",
      "\n",
      "        Args:\n",
      "            detection (Results): YOLO detection results for a single frame.\n",
      "\n",
      "        Returns:\n",
      "            dict: Tracking data.\n",
      "        \"\"\"\n",
      "        pass\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "PREFIX:\n",
      "from tracking.abstract_tracker import AbstractTracker\n",
      "\n",
      "import supervision as sv\n",
      "import cv2\n",
      "from typing import List\n",
      "import numpy as np\n",
      "from ultralytics.engine.results import Results\n",
      "\n",
      "class ObjectTracker(AbstractTracker):\n",
      "\n",
      "    def __init__(self, model_path: str, conf: float = 0.5, ball_conf: float = 0.3) -> None:\n",
      "        \"\"\"\n",
      "        Initialize ObjectTracker with detection and tracking.\n",
      "\n",
      "        Args:\n",
      "            model_path (str): Model Path.\n",
      "            conf (float): Confidence threshold for detection.\n",
      "        \"\"\"\n",
      "        super().__init__(model_path, conf)  # Call the Tracker base class constructor\n",
      "\n",
      "        self.ball_conf = ball_conf\n",
      "        self.classes = ['ball', 'goalkeeper', 'player', 'referee']\n",
      "        self.tracker = sv.ByteTrack(lost_track_buffer=5)  # Initialize ByteTracker\n",
      "        self.tracker.reset()\n",
      "        self.all_tracks = {class_name: {} for class_name in self.classes}  # Initialize tracks\n",
      "        self.cur_frame = 0  # Frame counter initialization\n",
      "        self.original_size = (1920, 1080)  # Original frame size (1920x1080)\n",
      "        self.scale_x = self.original_size[0] / 1280\n",
      "        self.scale_y = self.original_size[1] / 1280\n",
      "\n",
      "    def detect(self, frames: List[np.ndarray]) -> List[Results]:\n",
      "**************************************************\n",
      "\n",
      "MIDDLE TRUE:\n",
      "nan\n",
      "**************************************************\n",
      "\n",
      "SUFFIX:\n",
      "        \"\"\"\n",
      "        Perform object detection on multiple frames.\n",
      "\n",
      "        Args:\n",
      "            frames (List[np.ndarray]): List of frames to perform object detection on.\n",
      "\n",
      "        Returns:\n",
      "            List[Results]: Detection results for each frame.\n",
      "        \"\"\"\n",
      "        # Preprocess: Resize frames to 1280x1280\n",
      "        resized_frames = [self._preprocess_frame(frame) for frame in frames]\n",
      "\n",
      "        # Use YOLOv8's predict method to handle batch inference\n",
      "        detections = self.model.predict(resized_frames, conf=self.conf)\n",
      "\n",
      "        return detections  # Batch of detections\n",
      "\n",
      "    def track(self, detection: Results) -> dict:\n",
      "        \"\"\"\n",
      "        Perform object tracking on detection.\n",
      "\n",
      "        Args:\n",
      "            detection (Results): Detected objects for a single frame.\n",
      "\n",
      "        Returns:\n",
      "            dict: Dictionary containing tracks of the frame.\n",
      "        \"\"\"\n",
      "        # Convert Ultralytics detections to supervision\n",
      "        detection_sv = sv.Detections.from_ultralytics(detection)\n",
      "\n",
      "        # Perform ByteTracker object tracking on the detections\n",
      "        tracks = self.tracker.update_with_detections(detection_sv)\n",
      "\n",
      "        self.current_frame_tracks = self._tracks_mapper(tracks, self.classes)\n",
      "        \n",
      "        # Store the current frame's tracking information in all_tracks\n",
      "        self.all_tracks[self.cur_frame] = self.current_frame_tracks.copy()\n",
      "\n",
      "        # Increment the current frame counter\n",
      "        self.cur_frame += 1\n",
      "\n",
      "        # Return only the last frame's data\n",
      "        return self.current_frame_tracks\n",
      "    \n",
      "    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Preprocess the frame by resizing it to 1280x1280.\n",
      "\n",
      "        Args:\n",
      "            frame (np.ndarray): The input image frame.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The resized frame.\n",
      "        \"\"\"\n",
      "        # Resize the frame to 1280x1280\n",
      "        resized_frame = cv2.resize(frame, (1280, 1280))\n",
      "        return resized_frame\n",
      "    \n",
      "    def _tracks_mapper(self, tracks: sv.Detections, class_names: List[str]) -> dict:\n",
      "        \"\"\"\n",
      "        Maps tracks to a dictionary by class and tracker ID. Also, adjusts bounding boxes to 1920x1080 resolution.\n",
      "\n",
      "        Args:\n",
      "            tracks (sv.Detections): Tracks from the frame.\n",
      "            class_names (List[str]): List of class names.\n",
      "\n",
      "        Returns:\n",
      "            dict: Mapped detections for the frame.\n",
      "        \"\"\"\n",
      "        # Initialize the dictionary\n",
      "        result = {class_name: {} for class_name in class_names}\n",
      "\n",
      "        # Extract relevant data from tracks\n",
      "        xyxy = tracks.xyxy  # Bounding boxes\n",
      "        class_ids = tracks.class_id  # Class IDs\n",
      "        tracker_ids = tracks.tracker_id  # Tracker IDs\n",
      "        confs = tracks.confidence\n",
      "\n",
      "        # Iterate over all tracks\n",
      "        for bbox, class_id, track_id, conf in zip(xyxy, class_ids, tracker_ids, confs):\n",
      "            class_name = class_names[class_id]\n",
      "\n",
      "            # Skip balls with confidence lower than ball_conf\n",
      "            if class_name == \"ball\" and conf < self.ball_conf:\n",
      "                continue  # Skip low-confidence ball detections\n",
      "\n",
      "            # Create class_name entry if not already present\n",
      "            if class_name not in result:\n",
      "                result[class_name] = {}\n",
      "\n",
      "            # Scale the bounding box back to the original resolution (1920x1080)\n",
      "            scaled_bbox = [\n",
      "                bbox[0] * self.scale_x,  # x1\n",
      "                bbox[1] * self.scale_y,  # y1\n",
      "                bbox[2] * self.scale_x,  # x2\n",
      "                bbox[3] * self.scale_y   # y2\n",
      "            ]\n",
      "\n",
      "            # Add track_id entry if not already present\n",
      "            if track_id not in result[class_name]:\n",
      "                result[class_name][track_id] = {'bbox': scaled_bbox}\n",
      "\n",
      "        return result\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "PREFIX:\n",
      "from .abstract_annotator import AbstractAnnotator\n",
      "from .abstract_video_processor import AbstractVideoProcessor\n",
      "from .object_annotator import ObjectAnnotator\n",
      "from .keypoints_annotator import KeypointsAnnotator\n",
      "from .projection_annotator import ProjectionAnnotator\n",
      "from position_mappers import ObjectPositionMapper\n",
      "from speed_estimation import SpeedEstimator\n",
      "from .frame_number_annotator import FrameNumberAnnotator\n",
      "from file_writing import TracksJsonWriter\n",
      "from tracking import ObjectTracker, KeypointsTracker\n",
      "from club_assignment import ClubAssigner\n",
      "from ball_to_player_assignment import BallToPlayerAssigner\n",
      "from utils import rgb_bgr_converter\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "from typing import List, Dict, Optional, Tuple\n",
      "\n",
      "class FootballVideoProcessor(AbstractAnnotator, AbstractVideoProcessor):\n",
      "    \"\"\"\n",
      "    A video processor for football footage that tracks objects and keypoints,\n",
      "    estimates speed, assigns the ball to player, calculates the ball possession \n",
      "    and adds various annotations.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, obj_tracker: ObjectTracker, kp_tracker: KeypointsTracker, \n",
      "**************************************************\n",
      "\n",
      "MIDDLE TRUE:\n",
      "                 club_assigner: ClubAssigner, ball_to_player_assigner: BallToPlayerAssigner, \n",
      "                 top_down_keypoints: np.ndarray, field_img_path: str, \n",
      "                 save_tracks_dir: Optional[str] = None, draw_frame_num: bool = True) -> None:\n",
      "        \"\"\"\n",
      "        Initializes the video processor with necessary components for tracking, annotations, and saving tracks.\n",
      "\n",
      "        Args:\n",
      "            obj_tracker (ObjectTracker): The object tracker for tracking players and balls.\n",
      "            kp_tracker (KeypointsTracker): The keypoints tracker for detecting and tracking keypoints.\n",
      "            club_assigner (ClubAssigner): Assigner to determine clubs for the tracked players.\n",
      "            ball_to_player_assigner (BallToPlayerAssigner): Assigns the ball to a specific player based on tracking.\n",
      "            top_down_keypoints (np.ndarray): Keypoints to map objects to top-down positions.\n",
      "            field_img_path (str): Path to the image of the football field used for projection.\n",
      "            save_tracks_dir (Optional[str]): Directory to save tracking information. If None, no tracks will be saved.\n",
      "            draw_frame_num (bool): Whether or not to draw current frame number on the output video.\n",
      "        \"\"\"\n",
      "\n",
      "        self.obj_tracker = obj_tracker\n",
      "        self.obj_annotator = ObjectAnnotator()\n",
      "        self.kp_tracker = kp_tracker\n",
      "        self.kp_annotator = KeypointsAnnotator()\n",
      "        self.club_assigner = club_assigner\n",
      "        self.ball_to_player_assigner = ball_to_player_assigner\n",
      "        self.projection_annotator = ProjectionAnnotator()\n",
      "        self.obj_mapper = ObjectPositionMapper(top_down_keypoints)\n",
      "        self.draw_frame_num = draw_frame_num\n",
      "        if self.draw_frame_num:\n",
      "            self.frame_num_annotator = FrameNumberAnnotator() \n",
      "\n",
      "        if save_tracks_dir:\n",
      "            self.save_tracks_dir = save_tracks_dir\n",
      "            self.writer = TracksJsonWriter(save_tracks_dir)\n",
      "        \n",
      "        field_image = cv2.imread(field_img_path)\n",
      "        # Convert the field image to grayscale (black and white)\n",
      "        field_image = cv2.cvtColor(field_image, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "        # Convert grayscale back to 3 channels (since the main frame is 3-channel)\n",
      "        field_image = cv2.cvtColor(field_image, cv2.COLOR_GRAY2BGR)\n",
      "\n",
      "        # Initialize the speed estimator with the field image's dimensions\n",
      "        self.speed_estimator = SpeedEstimator(field_image.shape[1], field_image.shape[0])\n",
      "        \n",
      "        self.frame_num = 0\n",
      "\n",
      "        self.field_image = field_image\n",
      "\n",
      "    def process(self, frames: List[np.ndarray], fps: float = 1e-6) -> List[np.ndarray]:\n",
      "        \"\"\"\n",
      "        Processes a batch of video frames, detects and tracks objects, assigns ball possession, and annotates the frames.\n",
      "\n",
      "        Args:\n",
      "            frames (List[np.ndarray]): List of video frames.\n",
      "            fps (float): Frames per second of the video, used for speed estimation.\n",
      "\n",
      "        Returns:\n",
      "            List[np.ndarray]: A list of annotated video frames.\n",
      "        \"\"\"\n",
      "        \n",
      "        self.cur_fps = max(fps, 1e-6)\n",
      "\n",
      "        # Detect objects and keypoints in all frames\n",
      "        batch_obj_detections = self.obj_tracker.detect(frames)\n",
      "        batch_kp_detections = self.kp_tracker.detect(frames)\n",
      "\n",
      "        processed_frames = []\n",
      "\n",
      "        # Process each frame in the batch\n",
      "        for idx, (frame, object_detection, kp_detection) in enumerate(zip(frames, batch_obj_detections, batch_kp_detections)):\n",
      "            \n",
      "            # Track detected objects and keypoints\n",
      "            obj_tracks = self.obj_tracker.track(object_detection)\n",
      "            kp_tracks = self.kp_tracker.track(kp_detection)\n",
      "\n",
      "            # Assign clubs to players based on their tracked position\n",
      "            obj_tracks = self.club_assigner.assign_clubs(frame, obj_tracks)\n",
      "\n",
      "            all_tracks = {'object': obj_tracks, 'keypoints': kp_tracks}\n",
      "\n",
      "            # Map objects to a top-down view of the field\n",
      "            all_tracks = self.obj_mapper.map(all_tracks)\n",
      "\n",
      "            # Assign the ball to the closest player and calculate speed\n",
      "            all_tracks['object'], _ = self.ball_to_player_assigner.assign(\n",
      "                all_tracks['object'], self.frame_num, \n",
      "                all_tracks['keypoints'].get(8, None),  # keypoint for player 1\n",
      "                all_tracks['keypoints'].get(24, None)  # keypoint for player 2\n",
      "            )\n",
      "\n",
      "            # Estimate the speed of the tracked objects\n",
      "            all_tracks['object'] = self.speed_estimator.calculate_speed(\n",
      "                all_tracks['object'], self.frame_num, self.cur_fps\n",
      "            )\n",
      "            \n",
      "            # Save tracking information if saving is enabled\n",
      "            if self.save_tracks_dir:\n",
      "                self._save_tracks(all_tracks)\n",
      "\n",
      "            self.frame_num += 1\n",
      "\n",
      "            # Annotate the current frame with the tracking information\n",
      "            annotated_frame = self.annotate(frame, all_tracks)\n",
      "\n",
      "            # Append the annotated frame to the processed frames list\n",
      "            processed_frames.append(annotated_frame)\n",
      "\n",
      "        return processed_frames\n",
      "\n",
      "    \n",
      "    def annotate(self, frame: np.ndarray, tracks: Dict) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Annotates the given frame with analised data\n",
      "\n",
      "        Args:\n",
      "            frame (np.ndarray): The current video frame to be annotated.\n",
      "            tracks (Dict[str, Dict[int, np.ndarray]]): A dictionary containing tracking data for objects and keypoints.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The annotated video frame.\n",
      "        \"\"\"\n",
      "         \n",
      "        # Draw the frame number if required\n",
      "        if self.draw_frame_num:\n",
      "            frame = self.frame_num_annotator.annotate(frame, {'frame_num': self.frame_num})\n",
      "        \n",
      "        # Annotate the frame with keypoint and object tracking information\n",
      "        frame = self.kp_annotator.annotate(frame, tracks['keypoints'])\n",
      "        frame = self.obj_annotator.annotate(frame, tracks['object'])\n",
      "        \n",
      "        # Project the object positions onto the football field image\n",
      "        projection_frame = self.projection_annotator.annotate(self.field_image, tracks['object'])\n",
      "\n",
      "        # Combine the frame and projection into a single canvas\n",
      "        combined_frame = self._combine_frame_projection(frame, projection_frame)\n",
      "\n",
      "        # Annotate possession on the combined frame\n",
      "        combined_frame = self._annotate_possession(combined_frame)\n",
      "\n",
      "        return combined_frame\n",
      "    \n",
      "\n",
      "    def _combine_frame_projection(self, frame: np.ndarray, projection_frame: np.ndarray) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Combines the original video frame with the projection of player positions on the field image.\n",
      "\n",
      "        Args:\n",
      "            frame (np.ndarray): The original video frame.\n",
      "            projection_frame (np.ndarray): The projected field image with annotations.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The combined frame.\n",
      "        \"\"\"\n",
      "        # Target canvas size\n",
      "        canvas_width, canvas_height = 1920, 1080\n",
      "        \n",
      "        # Get dimensions of the original frame and projection frame\n",
      "        h_frame, w_frame, _ = frame.shape\n",
      "        h_proj, w_proj, _ = projection_frame.shape\n",
      "\n",
      "        # Scale the projection to 70% of its original size\n",
      "        scale_proj = 0.7\n",
      "        new_w_proj = int(w_proj * scale_proj)\n",
      "        new_h_proj = int(h_proj * scale_proj)\n",
      "        projection_resized = cv2.resize(projection_frame, (new_w_proj, new_h_proj))\n",
      "\n",
      "        # Create a blank canvas of 1920x1080\n",
      "        combined_frame = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
      "\n",
      "        # Copy the main frame onto the canvas (top-left corner)\n",
      "        combined_frame[:h_frame, :w_frame] = frame\n",
      "\n",
      "        # Set the position for the projection frame at the bottom-middle\n",
      "        x_offset = (canvas_width - new_w_proj) // 2\n",
      "        y_offset = canvas_height - new_h_proj - 25  # 25px margin from bottom\n",
      "\n",
      "        # Blend the projection with 75% visibility (alpha transparency)\n",
      "        alpha = 0.75\n",
      "        overlay = combined_frame[y_offset:y_offset + new_h_proj, x_offset:x_offset + new_w_proj]\n",
      "        cv2.addWeighted(projection_resized, alpha, overlay, 1 - alpha, 0, overlay)\n",
      "\n",
      "        return combined_frame\n",
      "    \n",
      "\n",
      "    def _annotate_possession(self, frame: np.ndarray) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Annotates the possession progress bar on the top-left of the frame.\n",
      "\n",
      "        Args:\n",
      "            frame (np.ndarray): The frame to be annotated.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: The annotated frame with possession information.\n",
      "        \"\"\"\n",
      "        frame = frame.copy()\n",
      "        overlay = frame.copy()\n",
      "\n",
      "        # Position and size for the possession overlay (top-left with 20px margin)\n",
      "        overlay_width = 500\n",
      "        overlay_height = 100\n",
      "        gap_x = 20  # 20px from the left\n",
      "        gap_y = 20  # 20px from the top\n",
      "\n",
      "        # Draw background rectangle (black with transparency)\n",
      "        cv2.rectangle(overlay, (gap_x, gap_y), (gap_x + overlay_width, gap_y + overlay_height), (0, 0, 0), -1)\n",
      "        alpha = 0.4\n",
      "        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
      "\n",
      "        # Position for possession text\n",
      "        text_x = gap_x + 15\n",
      "        text_y = gap_y + 30\n",
      "\n",
      "        # Display \"Possession\" above the progress bar\n",
      "        cv2.putText(frame, 'Possession:', (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, .7, (255, 255, 255), 1)\n",
      "\n",
      "        # Position and size for the possession bar (20px margin)\n",
      "        bar_x = text_x\n",
      "        bar_y = text_y + 25\n",
      "        bar_width = overlay_width - bar_x\n",
      "        bar_height = 15\n",
      "\n",
      "        # Get possession data from the ball-to-player assigner\n",
      "        possession = self.ball_to_player_assigner.get_ball_possessions()[-1]\n",
      "        possession_club1 = possession[0]\n",
      "        possession_club2 = possession[1]\n",
      "\n",
      "        # Calculate sizes for each possession segment in pixels\n",
      "        club1_width = int(bar_width * possession_club1)\n",
      "        club2_width = int(bar_width * possession_club2)\n",
      "        neutral_width = bar_width - club1_width - club2_width\n",
      "\n",
      "        club1_color = self.club_assigner.club1.player_jersey_color\n",
      "        club2_color = self.club_assigner.club2.player_jersey_color\n",
      "        neutral_color = (128, 128, 128)\n",
      "\n",
      "        # Convert Club Colors from RGB to BGR\n",
      "        club1_color = rgb_bgr_converter(club1_color)\n",
      "        club2_color = rgb_bgr_converter(club2_color)\n",
      "\n",
      "        # Draw club 1's possession (left)\n",
      "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + club1_width, bar_y + bar_height), club1_color, -1)\n",
      "\n",
      "        # Draw neutral possession (middle)\n",
      "        cv2.rectangle(frame, (bar_x + club1_width, bar_y), (bar_x + club1_width + neutral_width, bar_y + bar_height), neutral_color, -1)\n",
      "\n",
      "        # Draw club 2's possession (right)\n",
      "        cv2.rectangle(frame, (bar_x + club1_width + neutral_width, bar_y), (bar_x + bar_width, bar_y + bar_height), club2_color, -1)\n",
      "\n",
      "        # Draw outline for the entire progress bar\n",
      "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (0, 0, 0), 2)\n",
      "\n",
      "        # Calculate the position for the possession text under the bars\n",
      "        possession_club1_text = f'{int(possession_club1 * 100)}%'\n",
      "        possession_club2_text = f'{int(possession_club2 * 100)}%'\n",
      "\n",
      "        # Display possession percentages for each club\n",
      "        self._display_possession_text(frame, club1_width, club2_width, neutral_width, bar_x, bar_y, possession_club1_text, possession_club2_text, club1_color, club2_color)\n",
      "\n",
      "        return frame\n",
      "    \n",
      "\n",
      "    def _display_possession_text(self, frame: np.ndarray, club1_width: int, club2_width: int,\n",
      "                                  neutral_width: int, bar_x: int, bar_y: int, \n",
      "                                 possession_club1_text: str, possession_club2_text: str, \n",
      "                                 club1_color: Tuple[int, int, int], club2_color: Tuple[int, int, int]) -> None:\n",
      "        \"\"\"\n",
      "        Helper function to display possession percentages for each club below the progress bar.\n",
      "\n",
      "        Args:\n",
      "            frame (np.ndarray): The frame where the text will be displayed.\n",
      "            club1_width (int): Width of club 1's possession bar.\n",
      "            club2_width (int): Width of club 2's possession bar.\n",
      "            neutral_width (int): Width of the neutral possession area.\n",
      "            bar_x (int): X-coordinate of the progress bar.\n",
      "            bar_y (int): Y-coordinate of the progress bar.\n",
      "            possession_club1_text (str): Text for club 1's possession percentage.\n",
      "            possession_club2_text (str): Text for club 2's possession percentage.\n",
      "            club1_color (tuple): BGR color of club 1.\n",
      "            club2_color (tuple): BGR color of club 2.\n",
      "        \"\"\"\n",
      "        # Text for club 1\n",
      "        club1_text_x = bar_x + club1_width // 2 - 10  # Center of club 1's possession bar\n",
      "        club1_text_y = bar_y + 35  # 20 pixels below the bar\n",
      "        cv2.putText(frame, possession_club1_text, (club1_text_x, club1_text_y), \n",
      "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)  # Black outline\n",
      "        cv2.putText(frame, possession_club1_text, (club1_text_x, club1_text_y), \n",
      "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, club1_color, 1)  # Club 1's color\n",
      "\n",
      "        # Text for club 2\n",
      "        club2_text_x = bar_x + club1_width + neutral_width + club2_width // 2 - 10  # Center of club 2's possession bar\n",
      "        club2_text_y = bar_y + 35  # 20 pixels below the bar\n",
      "        cv2.putText(frame, possession_club2_text, (club2_text_x, club2_text_y), \n",
      "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)  # Black outline\n",
      "        cv2.putText(frame, possession_club2_text, (club2_text_x, club2_text_y), \n",
      "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, club2_color, 1)  # Club 2's color\n",
      "\n",
      "\n",
      "\n",
      "    def _save_tracks(self, all_tracks: Dict[str, Dict[int, np.ndarray]]) -> None:\n",
      "**************************************************\n",
      "\n",
      "SUFFIX:\n",
      "        \"\"\"\n",
      "        Saves the tracking information for objects and keypoints to the specified directory.\n",
      "\n",
      "        Args:\n",
      "            all_tracks (Dict[str, Dict[int, np.ndarray]]): A dictionary containing tracking data for objects and keypoints.\n",
      "        \"\"\"\n",
      "        self.writer.write(self.writer.get_object_tracks_path(), all_tracks['object'])\n",
      "        self.writer.write(self.writer.get_keypoints_tracks_path(), all_tracks['keypoints'])\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\nPREFIX:')\n",
    "    print(df['prefix'][i])\n",
    "    print('*'*50)\n",
    "    print('\\nMIDDLE TRUE:')\n",
    "    print(df['middle'][i])\n",
    "    print('*'*50)\n",
    "    print('\\nSUFFIX:')\n",
    "    print(df['suffix'][i])\n",
    "    print('_'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX:\n",
      "                    color = track_info.get('club_color', (255, 255, 255))\n",
      "\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      "                            shape = 'circle' if class_name == 'goalkeeper' else 'square'\n",
      "                            self._draw_outline(frame, proj_pos, shape=shape, is_dark=is_dark_color)\n",
      "\n",
      "                            if track_info.get('has_ball', False):\n",
      "<|endoftext|>\n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      "                    color = rgb_bgr_converter(color)\n",
      "\n",
      "**************************************************\n",
      "SUFFIX:\n",
      "                    is_dark_color = is_color_dark(color)\n",
      "\n",
      "                    if class_name in ['player', 'goalkeeper']:\n",
      "                        shape = 'square' if class_name == 'goalkeeper' else 'circle'\n",
      "                        self._draw_outline(frame, proj_pos, shape=shape, is_dark=is_dark_color)\n",
      "\n",
      "                        if track_info.get('has_ball', False):\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      "from club_assignment import Club\n",
      "\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      "\n",
      "class ClubAssignment:\n",
      "    def __init__(self, club1: Club, club2: Club):\n",
      "        self.club1: Club = club1\n",
      "        self.club2: Club = club2\n",
      "\n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      "\n",
      "from typing import Dict, List\n",
      "\n",
      "class PossessionTracker:\n",
      "    \"\"\"Tracking the ball possession of each club\"\"\"\n",
      "\n",
      "    def __init__(self, club1: Club, club2: Club) -> None:\n",
      "        \"\"\"\n",
      "        Initializes the PossessionTracker with club names and possession statistics.\n",
      "\n",
      "        Args:\n",
      "            club1 (Club): The first club object\n",
      "            club2 (Club): The second club object\n",
      "        \"\"\"\n",
      "\n",
      "**************************************************\n",
      "SUFFIX:\n",
      "        self.possession_dict: Dict[str, int] = {-1: 0, club1.name: 0, club2.name: 0}\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      "                    print(f\"Thread {thread.name} did not terminate gracefully\")\n",
      "\n",
      "            # Ensure all queues are empty\n",
      "            while not frame_queue.empty():\n",
      "                frame_queue.get()\n",
      "            while not processed_queue.empty():\n",
      "                processed_queue.get()\n",
      "\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      "            while not frame_queue.empty():\n",
      "                frame_queue.get()\n",
      "            while not processed_queue.empty():\n",
      "                processed_queue.get()\n",
      "\n",
      "            # Stop the thread\n",
      "            thread.join()\n",
      "            print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "        # Stop the thread\n",
      "        thread.join()\n",
      "        print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "    # Stop the thread\n",
      "    thread.join()\n",
      "    print(\"Thread %s terminated gracefully\" % thread.name)\n",
      "\n",
      "   \n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      "\n",
      "            print(\"All threads have completed.\")\n",
      "            # Only convert to video if output_video is not None\n",
      "\n",
      "**************************************************\n",
      "SUFFIX:\n",
      "            if output_video is not None:\n",
      "                print(\"Converting frames to video...\")\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      "                 fps: int = 30, \n",
      "                 max_ball_speed: float = 250.0, \n",
      "                 speed_check_frames: int = 5, \n",
      "                 penalty_point_distance: float = 15.0) -> None:\n",
      "\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      "        \"\"\"\n",
      "\n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      "        \"\"\"\n",
      "        Initializes the BallToPlayerAssigner with necessary parameters.\n",
      "\n",
      "\n",
      "**************************************************\n",
      "SUFFIX:\n",
      "        Args:\n",
      "            club1 (Club): The Club object of the first club.\n",
      "            club2 (Club): The Club object of the second club.\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "PREFIX:\n",
      "            # Wait for user to press 'q'\n",
      "            while any(thread.is_alive() for thread in threads):\n",
      "                if stop_event.is_set():\n",
      "                    print(\"Stopping threads...\")\n",
      "                    break\n",
      "                time.sleep(0.1)\n",
      "\n",
      "            stop_event.set()  # Ensure all threads know to stop\n",
      "\n",
      "**************************************************\n",
      "MIDDLE PREDICTION:\n",
      "            print(\"Stopping threads...\")\n",
      "            threads.remove(thread)  # Remove the thread from the list\n",
      "            print(\"Threads stopped\")\n",
      "\n",
      "        except KeyboardInterrupt:\n",
      "            print(\"KeyboardInterrupt\")\n",
      "            stop_event.set()  # Ensure all threads know to stop\n",
      "\n",
      "    except Exception as e:\n",
      "        print(e)\n",
      "        stop_event.set()  # Ensure all threads know to stop\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    try:\n",
      "        # Create a thread to run the program\n",
      "        threads = []\n",
      "        for i in range(10):\n",
      "            thread = threading.Thread(target=run_program, args=(i,))\n",
      "            thread.start()\n",
      "            threads.append(thread)\n",
      "\n",
      "        # Wait for all threads to finish\n",
      "        for thread in threads:\n",
      "<|endoftext|>\n",
      "**************************************************\n",
      "MIDDLE TRUE:\n",
      "\n",
      "            for thread in threads:\n",
      "\n",
      "**************************************************\n",
      "SUFFIX:\n",
      "                thread.join(timeout=10)  # Give each thread 10 seconds to join\n",
      "                if thread.is_alive():\n",
      "\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res = df.drop(columns=['fname']).copy()\n",
    "\n",
    "res['mid_pred'] = preds\n",
    "\n",
    "for i in range(5):\n",
    "    print('PREFIX:')\n",
    "    print(res['prefix'][i])\n",
    "    print('*'*50)\n",
    "    print('MIDDLE PREDICTION:')\n",
    "    print(res['mid_pred'][i])\n",
    "    print('*'*50)\n",
    "    print('MIDDLE TRUE:')\n",
    "    print(res['middle'][i])\n",
    "    print('*'*50)\n",
    "    print('SUFFIX:')\n",
    "    print(res['suffix'][i])\n",
    "    print('_'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
